{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto final. Optimización\n",
    "### Globally linearly convergent nonlinear conjugate gradients withoutWolfe line search\n",
    "\n",
    "+ Gonzales Valadez Ulises Aldair\n",
    "+ Segura Gómez Guillermo\n",
    "\n",
    "Seleccionar un artículo para el proyecto final.\n",
    "\n",
    "- El proyecto final se puede presentar de manera individual o en equipo \n",
    "  formado por dos estudiantes.\n",
    "- La entrega del proyecto consiste programar el algoritmo descrito \n",
    "  en el artículo seleccionado y realizar pruebas para reproducir algunos resultados\n",
    "  presentados en el artículo o diseñar los experimentos de prueba. El objetivo es\n",
    "  mostrar las ventajas o limitaciones que tiene el algoritmo propuesto.\n",
    "- Es válido delimitar el alcance, de manera que si aparecen varios algoritmos\n",
    "  en el artículo, se puede seleccionar alguno de ellos para su implementación y validación.\n",
    "- Hay que elaborar un reporte en el que se dé una introducción, \n",
    "  algunos fundamentos teóricos, el planteamiento del problema, la descripción del algoritmo, \n",
    "  los resultados obtenidos y las conclusiones.\n",
    "- Hay que hacer una presentación de unos 15 minutos en el día acordado y \n",
    "  entregar el reporte, el código y las pruebas realizadas.\n",
    "- Se puede entregar un notebook como el reporte y usarlo en la presentación,\n",
    "  para que no tener que elaborar un documento con el reporte, otro con el script \n",
    "  del código y pruebas y otro para la presentación.\n",
    "- Habrá dos fechas de entrega. La primera fecha es para los estudiantes de posgrado \n",
    "  que será entre el 27 de mayo y el 4 de junio. La segunda fecha es para los estudiantes \n",
    "  de licenciatura que será entre el 3 de junio y el 10 de junio.\n",
    "- Si el equipo está formado por un estudiante de licenciatura y otro de posgrado\n",
    "  tendrá que presentar el proyecto en la primera fecha.\n",
    "- Para la selección se puede tomar uno de los artículos de la lista \n",
    "  que se presenta a continuación. \n",
    "- Estos artículos son una referencia. También pueden proponer algún artículo adicional,\n",
    "  pero recomienda que cuiden que para entenderlo no tengan que revisar otras fuentes\n",
    "  o que tengan que implementar algoritmos que requieran de temas que no fueron cubiertos\n",
    "  en el curso y que les consuma demasiado tiempo hacer esa revisión, por ejemplo, \n",
    "  en temas de optimización combinatoria, entera, mixta, multiobjetivo, etc.\n",
    "\n",
    "1. Escriba el nombre de los miembros del equipo junto con el nombre del programa académico.\n",
    "2. Escriba el título del artículo seleccionado\n",
    "3. Si no es un artículo de la lista o que esté en el Classroom, agregue el PDF\n",
    "   como parte de la entrega de la Tarea 7.\n",
    "\n",
    "\n",
    "## Introduccion\n",
    "\n",
    "**Título:** \"Globally linearly convergent nonlinear conjugate gradients without Wolfe line search\"\n",
    "\n",
    "**Autores:** Arnold Neumaier, Morteza Kimiaei, Behzad Azmi\n",
    "\n",
    "#### Resumen:\n",
    "El artículo introduce un nuevo método de gradiente conjugado no lineal (CG) que no requiere la condición de Wolfe para la búsqueda de líneas. Este método es globalmente convergente a un punto estacionario para funciones objetivo diferenciables con gradiente Lipschitz continuo y es linealmente convergente si este punto estacionario es un minimizador local fuerte. También se presenta una medida para la fuerza de zigzag y una dirección mínima de zigzag. El método propuesto es competitivo con los mejores métodos CG no lineales del estado del arte según resultados numéricos en problemas de prueba CUTEst.\n",
    "\n",
    "\n",
    "### Métodos de Gradiente Conjugado No Lineal\n",
    "\n",
    "Los métodos de gradiente conjugado no lineal se utilizan principalmente para resolver problemas de optimización sin restricciones donde la función objetivo no es necesariamente convexa. Estos métodos son útiles para encontrar mínimos locales de funciones diferenciables y son especialmente eficaces en problemas grandes y dispersos, como aquellos que aparecen en el aprendizaje automático, la simulación numérica y la investigación operativa [2].\n",
    "\n",
    "Los métodos de gradiente conjugado no lineal mejoran sobre el método de descenso más pronunciado al generar direcciones de búsqueda conjugadas, lo que puede llevar a una convergencia más rápida. En particular, se evitan los problemas de zigzagueo que son comunes en el método de descenso más pronunciado.\n",
    "\n",
    "### Condiciones de Wolfe para la Búsqueda en Línea\n",
    "\n",
    "Las condiciones de Wolfe son criterios usados en la búsqueda en línea para asegurar que la dirección de búsqueda y el tamaño de paso sean apropiados. Hay dos condiciones de Wolfe:\n",
    "\n",
    "1. **Condición de Wolfe de Armijo (Condición de Suficiente Descenso):**\n",
    "\n",
    "   $$\n",
    "   f(x + \\alpha p) \\leq f(x) + c_1 \\alpha \\nabla f(x)^T p\n",
    "   $$\n",
    "\n",
    "   Donde $0 < c_1 < 1$. Esta condición garantiza que el paso \\(\\alpha\\) proporciona una reducción suficiente en la función objetivo.\n",
    "\n",
    "2. **Condición de Curvatura de Wolfe:**\n",
    "\n",
    "   $$\n",
    "   \\nabla f(x + \\alpha p)^T p \\geq c_2 \\nabla f(x)^T p\n",
    "   $$\n",
    "\n",
    "   Donde $0 < c_1 < c_2 < 1$. Esta condición asegura que el paso no sea demasiado largo.\n",
    "\n",
    "### Gradiente de Lipschitz Continuo\n",
    "\n",
    "Un gradiente $\\nabla f(x)$ es Lipschitz continuo si existe una constante $L$ tal que para todos $x$ y $y$ en el dominio de $f$:\n",
    "\n",
    "$$\n",
    "\\|\\nabla f(x) - \\nabla f(y)\\| \\leq L \\|x - y\\|\n",
    "$$\n",
    "\n",
    "Esto implica que el gradiente de $f$ no cambia demasiado rápido, lo que es crucial para la convergencia de muchos algoritmos de optimización.\n",
    "\n",
    "### Fuerza de Zigzag\n",
    "\n",
    "La fuerza de zigzag se refiere al fenómeno donde las direcciones de búsqueda en un método de optimización oscilan entre direcciones opuestas, lo que puede llevar a una convergencia lenta. El zigzagging es común en el método de descenso más pronunciado y algunos métodos de gradiente conjugado no lineal buscan minimizar este efecto eligiendo direcciones de búsqueda que reduzcan esta oscilación.\n",
    "\n",
    "### Problemas de Prueba CUTEst\n",
    "\n",
    "CUTEst (Constrained and Unconstrained Testing Environment) es una colección de problemas de prueba usados para evaluar el rendimiento de algoritmos de optimización. Proporciona una amplia gama de problemas de optimización, tanto con restricciones como sin restricciones, que permiten a los investigadores comparar la eficiencia y la robustez de sus algoritmos en un entorno estandarizado.\n",
    "\n",
    "\n",
    "#### Algoritmo Propuesto:\n",
    "El nuevo algoritmo CG propuesto se llama NCG (Nonlinear Conjugate Gradient) y se detalla en el Algoritmo 2 del artículo. Este algoritmo utiliza una búsqueda de líneas eficiente que satisface una condición de descenso suficiente (condición 4) y una condición de reinicio para garantizar la convergencia lineal global.\n",
    "\n",
    "### Detalles del Algoritmo:\n",
    "\n",
    "#### 1. Medida de Zigzagging:\n",
    "El zigzagging se refiere al comportamiento ineficiente de las direcciones de búsqueda que puede ocurrir en métodos de descenso más pronunciado. Para evitar esto, el artículo define una medida de fuerza de zigzag y propone minimizar esta medida en cada iteración.\n",
    "\n",
    "#### 2. Dirección de Búsqueda:\n",
    "La dirección de búsqueda $p$ se elige minimizando la distancia preacondicionada al cuadrado desde la dirección de búsqueda anterior, lo que se llama medida de fuerza de zigzag. Esta dirección se obtiene mediante:\n",
    "\n",
    "$$ p = p_{\\text{old}} - \\lambda B^{-1}g $$\n",
    "\n",
    "donde $\\lambda$ se calcula como:\n",
    "\n",
    "$$ \\lambda = \\frac{\\nu + g^T p_{\\text{old}}}{g^T B^{-1}g} $$\n",
    "\n",
    "#### 3. Algoritmo Básico (NCG-basic):\n",
    "\n",
    "```plaintext\n",
    "1. Inicialización: \n",
    "   Entrada: x0 (punto inicial), B (preacondicionador), ε (umbral mínimo para la norma del gradiente).\n",
    "2. Para cada iteración:\n",
    "   1. Calcular g = ∇f(x), h = B^{-1}g, ω = g^T h.\n",
    "   2. Si ω ≤ ε^2, terminar (x es un punto estacionario).\n",
    "   3. Calcular λ y p usando las fórmulas dadas.\n",
    "   4. Determinar α mediante una búsqueda de líneas eficiente.\n",
    "   5. Actualizar x y f.\n",
    "3. Devolver x y f.\n",
    "```\n",
    "\n",
    "#### 4. Condición de Reinicio:\n",
    "Para asegurar la convergencia lineal global cuando se converge a un minimizador local fuerte, se usa una condición de reinicio que reemplaza una dirección de búsqueda deficiente por una dirección de Newton simplificada, usando un preacondicionador simétrico y definido positivo $B$.\n",
    "\n",
    "#### 5. Análisis de Complejidad:\n",
    "El artículo demuestra que el método NCG tiene una complejidad de $O(\\epsilon^{-2})$ para encontrar un punto estacionario y de $O(\\log(\\epsilon^{-1}))$ para funciones fuertemente convexas.\n",
    "\n",
    "### Implementación del Algoritmo NCG\n",
    "\n",
    "Para implementar el algoritmo NCG, se pueden seguir estos pasos en Python:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliografia\n",
    "\n",
    "1. **Métodos de Gradiente Conjugado No Lineal:**\n",
    "   - Nocedal, J., & Wright, S. J. (2006). *Numerical Optimization*. Springer.\n",
    "   - Fletcher, R. (1987). *Practical Methods of Optimization*. John Wiley & Sons.\n",
    "\n",
    "2. **Condiciones de Wolfe:**\n",
    "   - Nocedal, J., & Wright, S. J. (2006). *Numerical Optimization*. Springer.\n",
    "   - Wolfe, P. (1969). *Convergence conditions for ascent methods*. SIAM Review, 11(2), 226-235.\n",
    "\n",
    "3. **Gradiente de Lipschitz Continuo:**\n",
    "   - Boyd, S., & Vandenberghe, L. (2004). *Convex Optimization*. Cambridge University Press.\n",
    "   - Ciarlet, P. G. (1988). *Introduction to Numerical Linear Algebra and Optimization*. Cambridge University Press.\n",
    "\n",
    "4. **Fuerza de Zigzag:**\n",
    "   - Hager, W. W., & Zhang, H. (2005). *A survey of nonlinear conjugate gradient methods*. Pacific Journal of Optimization, 2(1), 35-58.\n",
    "   - Fletcher, R. (1987). *Practical Methods of Optimization*. John Wiley & Sons.\n",
    "\n",
    "5. **Problemas de Prueba CUTEst:**\n",
    "   - Gould, N. I., Orban, D., & Toint, P. L. (2003). *CUTEr and SifDec: A Constrained and Unconstrained Testing Environment, revisited*. ACM Transactions on Mathematical Software (TOMS), 29(4), 373-394.\n",
    "   - CUTEst official website: [http://www.cuter.rl.ac.uk](http://www.cuter.rl.ac.uk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def ncg_method(f, grad_f, x0, B, epsilon, max_iter):\n",
    "    def line_search(x, p, grad, f_value):\n",
    "        alpha = 1.0\n",
    "        beta = 0.02\n",
    "        while True:\n",
    "            new_x = x + alpha * p\n",
    "            new_f_value = f(new_x)\n",
    "            if new_f_value <= f_value + beta * alpha * np.dot(grad, p):\n",
    "                return alpha\n",
    "            alpha *= 0.5\n",
    "\n",
    "    x = x0\n",
    "    g = grad_f(x)\n",
    "    h = np.linalg.solve(B, g)\n",
    "    omega = np.dot(g, h)\n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "        if omega <= epsilon ** 2:\n",
    "            break\n",
    "        \n",
    "        if _ == 0 or np.any(restart_conditions_met(g, p, omega, k1, k2)):\n",
    "            p = -h\n",
    "        else:\n",
    "            lambda_ = (nu + np.dot(g, p)) / np.dot(g, h)\n",
    "            p = p - lambda_ * h\n",
    "        \n",
    "        alpha = line_search(x, p, g, f(x))\n",
    "        x = x + alpha * p\n",
    "        f_value = f(x)\n",
    "        \n",
    "        g_old = g\n",
    "        g = grad_f(x)\n",
    "        h = np.linalg.solve(B, g)\n",
    "        omega = np.dot(g, h)\n",
    "        \n",
    "        if restart_conditions_met(g, g_old, omega, k1, k2):\n",
    "            nu = omega\n",
    "            p = -h\n",
    "    \n",
    "    return x\n",
    "\n",
    "# Función objetivo y su gradiente\n",
    "def f(x):\n",
    "    return (x[0] - 1) ** 2 + (x[1] - 2) ** 2\n",
    "\n",
    "def grad_f(x):\n",
    "    return np.array([2 * (x[0] - 1), 2 * (x[1] - 2)])\n",
    "\n",
    "# Parámetros\n",
    "x0 = np.array([0.0, 0.0])\n",
    "B = np.eye(2)\n",
    "epsilon = 1e-6\n",
    "max_iter = 1000\n",
    "\n",
    "# Ejecución del algoritmo\n",
    "solution = ncg_method(f, grad_f, x0, B, epsilon, max_iter)\n",
    "print(\"Solución:\", solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notas:\n",
    "1. **Búsqueda de Líneas Eficiente:** En la función `line_search`, se implementa una búsqueda de líneas simple que satisface la condición de descenso suficiente.\n",
    "2. **Condiciones de Reinicio:** Las condiciones de reinicio se pueden personalizar según las necesidades específicas del problema.\n",
    "3. **Preacondicionador $B$:** En este ejemplo, se usa la matriz identidad como preacondicionador."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
