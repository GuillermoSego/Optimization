{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 6. Optimización\n",
    "Guillermo Segura Gómez\n",
    "\n",
    "## Ejercicio 1\n",
    "\n",
    "**1. Programe el método de gradiente conjugado lineal, Algoritmo 1 de la Clase 18, para resolver el sistema de ecuaciones $\\mathbf{A}\\mathbf{x}=\\mathbf{b}$, donde $\\mathbf{A}$ es una matriz simétrica y definida positiva.**\n",
    "   \n",
    "**Haga que la función devuelva el último punto  $\\mathbf{x}_k$, el último residual $\\mathbf{r}_k$, el número de iteraciones $k$ y una variable binaria $bres$ que indique si se cumplió el criterio de paro ($bres=True$) o si el algoritmo terminó por iteraciones ($bres=False$).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def ConjugateGradient(xk, A, b, nMax, tau):\n",
    "    rk = A @ xk - b\n",
    "    pk = -rk\n",
    "    for k in range(nMax):\n",
    "        \n",
    "        # Condición de parada\n",
    "        if np.linalg.norm(rk) < tau:\n",
    "            return xk, rk_next, True, k\n",
    "\n",
    "        Apk = A @ pk # Cálculo de Apk para optimizar\n",
    "\n",
    "        # Cálculo de alphak\n",
    "        rkTrk = rk.T @ rk\n",
    "        alphak = rkTrk / (pk.T @ Apk)\n",
    "        \n",
    "        # Siguiente valor de xk\n",
    "        xk = xk + alphak * pk\n",
    "        rk_next = rk + alphak * Apk\n",
    "        \n",
    "        betak = (rk_next.T @ rk_next) / rkTrk\n",
    "        pk = -rk_next + betak * pk\n",
    "        rk = rk_next\n",
    "\n",
    "    return xk, rk, False, nMax "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Pruebe el algoritmo para resolver el sistema de ecuaciones \n",
    "\n",
    "$$ \\mathbf{A}_1\\mathbf{x}=\\mathbf{b}_1$$\n",
    "\n",
    "donde\n",
    "\n",
    "$$ \\mathbf{A}_1 = n\\mathbf{I} + \\mathbf{1} = \n",
    "\\left[\\begin{array}{llll} n      & 0      & \\cdots & 0 \\\\\n",
    "                       0      & n      & \\cdots & 0 \\\\ \n",
    "                       \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "                       0      & 0      & \\cdots & n \\end{array}\\right]\n",
    "+ \\left[\\begin{array}{llll} 1    & 1      & \\cdots & 1 \\\\\n",
    "                       1      & 1      & \\cdots & 1 \\\\ \n",
    "                       \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "                       1      & 1      & a\\cdots & 1 \\end{array}\\right],  \\qquad\n",
    "\\mathbf{b}_1 = \\left[\\begin{array}{l} 1 \\\\ 1 \\\\ \\vdots \\\\ 1 \\end{array}\\right], $$\n",
    "\n",
    "$n$ es la dimensión de la variable independiente\n",
    "$\\mathbf{x}=(x_1, x_2, ..., x_n)$, \n",
    "$\\mathbf{I}$ es la matriz identidad y $\\mathbf{1}$ es la matriz llena de 1's,\n",
    "ambas de tamaño $n$.\n",
    "\n",
    "También aplique el algoritmo para resolver el sistema \n",
    "\n",
    "$$ \\mathbf{A}_2\\mathbf{x}=\\mathbf{b}_2$$\n",
    "\n",
    "donde  $\\mathbf{A}_2 = [a_{ij}]$ con\n",
    "\n",
    "$$ a_{ij} = exp\\left(-0.25(i-j)^2 \\right),  \\qquad\n",
    "\\mathbf{b}_2 = \\left[\\begin{array}{l} 1 \\\\ 1 \\\\ \\vdots \\\\ 1 \\end{array}\\right] $$\n",
    "\n",
    "\n",
    "- Use $\\mathbf{x}_0$ como el vector cero, el máximo número de iteraciones \n",
    "  $N=n$ y una toleracia $\\tau=\\sqrt{n} \\epsilon_m^{1/3}$,\n",
    "  donde $\\epsilon_m$ es el épsilon máquina.\n",
    "- Pruebe el algoritmo resolviendo los dos sistemas de ecuaciones con $n=10, 100, 1000$ y \n",
    "  en cada caso imprima la siguiente información\n",
    "\n",
    "- la dimensión $n$,\n",
    "- el  número $k$ de iteraciones realizadas,\n",
    "- las primeras y últimas 4 entradas del punto $\\mathbf{x}_k$ que devuelve el algoritmo,\n",
    "- la norma del residual $\\mathbf{r}_k$, \n",
    "- la variable $bres$ para saber si el algoritmo puedo converger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=10, Sistema A1\n",
      "  Iteraciones: 1\n",
      "  xk (primeras 4 entradas): [0.05 0.05 0.05 0.05]\n",
      "  xk (últimas 4 entradas): [0.05 0.05 0.05 0.05]\n",
      "  Norma del residual: 0.0\n",
      "  Convergencia: True\n",
      "n=10, Sistema A2\n",
      "  Iteraciones: 5\n",
      "  xk (primeras 4 entradas): [ 1.36909916 -1.16637682  1.60908281 -0.61339053]\n",
      "  xk (últimas 4 entradas): [-0.61339053  1.60908281 -1.16637682  1.36909916]\n",
      "  Norma del residual: 4.381415087263756e-12\n",
      "  Convergencia: True\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "n=100, Sistema A1\n",
      "  Iteraciones: 1\n",
      "  xk (primeras 4 entradas): [0.005 0.005 0.005 0.005]\n",
      "  xk (últimas 4 entradas): [0.005 0.005 0.005 0.005]\n",
      "  Norma del residual: 0.0\n",
      "  Convergencia: True\n",
      "n=100, Sistema A2\n",
      "  Iteraciones: 100\n",
      "  xk (primeras 4 entradas): [ 1.44625585 -1.41631711  2.11047274 -1.4249978 ]\n",
      "  xk (últimas 4 entradas): [-1.42500419  2.11047638 -1.41630417  1.4462564 ]\n",
      "  Norma del residual: 0.00016847652019634396\n",
      "  Convergencia: False\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "n=1000, Sistema A1\n",
      "  Iteraciones: 1\n",
      "  xk (primeras 4 entradas): [0.0005 0.0005 0.0005 0.0005]\n",
      "  xk (últimas 4 entradas): [0.0005 0.0005 0.0005 0.0005]\n",
      "  Norma del residual: 0.0\n",
      "  Convergencia: True\n",
      "n=1000, Sistema A2\n",
      "  Iteraciones: 262\n",
      "  xk (primeras 4 entradas): [ 1.44628824 -1.41635954  2.1105181  -1.42507231]\n",
      "  xk (últimas 4 entradas): [-1.42507231  2.1105181  -1.41635954  1.44628824]\n",
      "  Norma del residual: 0.00018766135470172154\n",
      "  Convergencia: True\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Función para generar A1 y b1\n",
    "def generate_A1_b1(n):\n",
    "    A1 = n * np.eye(n) + np.ones((n, n))\n",
    "    b1 = np.ones(n)\n",
    "    return A1, b1\n",
    "\n",
    "# Función para generar A2 y b2\n",
    "def generate_A2_b2(n):\n",
    "    A2 = np.array([[np.exp(-0.25 * (i - j) ** 2) for j in range(n)] for i in range(n)])\n",
    "    b2 = np.ones(n)\n",
    "    return A2, b2\n",
    "\n",
    "# Función para probar el algoritmo con las matrices y vectores dados\n",
    "def test_algorithm(n):\n",
    "    epsilon_m = np.finfo(float).eps  # Epsilon máquina\n",
    "    tau = np.sqrt(n) * (epsilon_m ** (1/3))  # Tolerancia\n",
    "    x0 = np.zeros(n)  # Vector inicial\n",
    "    nMax = n  # Número máximo de iteraciones\n",
    "\n",
    "    # Generar A1, b1 y aplicar el Gradiente Conjugado\n",
    "    A1, b1 = generate_A1_b1(n)\n",
    "    xk1, rk1, bres1, k1 = ConjugateGradient(x0, A1, b1, nMax, tau)\n",
    "\n",
    "    # Generar A2, b2 y aplicar el Gradiente Conjugado\n",
    "    A2, b2 = generate_A2_b2(n)\n",
    "    xk2, rk2, bres2, k2 = ConjugateGradient(x0, A2, b2, nMax, tau)\n",
    "\n",
    "    # Imprimir resultados para A1\n",
    "    print(f\"n={n}, Sistema A1\")\n",
    "    print(f\"  Iteraciones: {k1}\")\n",
    "    print(f\"  xk (primeras 4 entradas): {xk1[:4]}\")\n",
    "    print(f\"  xk (últimas 4 entradas): {xk1[-4:]}\")\n",
    "    print(f\"  Norma del residual: {np.linalg.norm(rk1)}\")\n",
    "    print(f\"  Convergencia: {bres1}\")\n",
    "\n",
    "    # Imprimir resultados para A2\n",
    "    print(f\"n={n}, Sistema A2\")\n",
    "    print(f\"  Iteraciones: {k2}\")\n",
    "    print(f\"  xk (primeras 4 entradas): {xk2[:4]}\")\n",
    "    print(f\"  xk (últimas 4 entradas): {xk2[-4:]}\")\n",
    "    print(f\"  Norma del residual: {np.linalg.norm(rk2)}\")\n",
    "    print(f\"  Convergencia: {bres2}\")\n",
    "\n",
    "# Prueba del algoritmo para n=10, 100, 1000\n",
    "for n in [10, 100, 1000]:\n",
    "    test_algorithm(n)\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que para el sistema $\\mathbf{A}_1\\mathbf{x}=\\mathbf{b}_1$, el algoritmo converge rápidamente (en 1 iteración) para todos los valores de $n$ probados. Esto se puede explicar con la simplicidad y estructura de la matriz $\\mathbf{A}_1$.\n",
    "\n",
    "Por otro lado, el sistema $\\mathbf{A}_2\\mathbf{x}=\\mathbf{b}_2$ presenta un mayor desafío, especialmente para $n=100$ donde no se logró la convergencia dentro del número máximo de iteraciones. Sin embargo, para $n=1000$, el algoritmo pudo converger, pero necesitó un mayor número de iteraciones (262), lo que indica la complejidad creciente del sistema con el aumento de $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "**Programar el método de gradiente conjugado no lineal descrito en el Algoritmo 3  de Clase 19 usando la fórmula de Fletcher-Reeves:**\n",
    "\n",
    "$$ \\beta_{k+1} = \\frac{\\nabla f_{k+1}^\\top \\nabla f_{k+1}}{\\nabla f_{k}^\\top\\nabla f_{k}}  $$ \n",
    "\n",
    "1. Escriba la función que implemente el algoritmo. \n",
    "\n",
    "- La función debe recibir como argumentos $\\mathbf{x}_0$, la función $f$ y \n",
    "  su gradiente, el número máximo de iteraciones $N$, la tolerancia $\\tau$, y los\n",
    "  parámetros para el algoritmo de backtracking: factor $\\rho$, la constante $c_1$\n",
    "  para la condición de descenso suficiente, la constante $c_2$ para la condición\n",
    "  de curvatura, y el máximo número de iteraciones $N_b$.\n",
    "- Agregue al algoritmo un contador\n",
    "  $nr$ que se incremente cada vez que se aplique el reinicio, es decir, cuando\n",
    "  se hace $\\beta_{k+1}=0$.\n",
    "   \n",
    "- Para calcular el tamaño de paso $\\alpha_k$ use el algoritmo de backtracking\n",
    "  usando las condiciones de Wolfe con el valor inicial $\\alpha_{ini}=1$.\n",
    "\n",
    "- Haga que la función devuelva el último punto  $\\mathbf{x}_k$, \n",
    "  el último gradiente $\\mathbf{g}_k$, el número de iteraciones $k$ \n",
    "  y una variable binaria $bres$ que indique si se cumpli\\'o el criterio\n",
    "  de paro ($bres=True$) o si el algoritmo terminó por\n",
    "  iteraciones ($bres=False$), y el contador $bres$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConjugateGrad_NLineal(nMax):\n",
    "\n",
    "    rk = A @ xk - b\n",
    "    pk = -rk\n",
    "    for k in range(nMax):\n",
    "        \n",
    "        # Condición de parada\n",
    "        if np.linalg.norm(rk) < tau:\n",
    "            return xk, rk_next, True, k\n",
    "\n",
    "        Apk = A @ pk # Cálculo de Apk para optimizar\n",
    "\n",
    "        # Cálculo de alphak\n",
    "        rkTrk = rk.T @ rk\n",
    "        alphak = rkTrk / (pk.T @ Apk)\n",
    "        \n",
    "        # Siguiente valor de xk\n",
    "        xk = xk + alphak * pk\n",
    "        rk_next = rk + alphak * Apk\n",
    "        \n",
    "        betak = (rk_next.T @ rk_next) / rkTrk\n",
    "        pk = -rk_next + betak * pk\n",
    "        rk = rk_next\n",
    "\n",
    "    return xk, rk, False, nMax "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Pruebe el algoritmo usando la siguientes funciones con los puntos iniciales dados:\n",
    "\n",
    "\n",
    "**Función de cuadrática 1:** Para $\\mathbf{x}=(x_1,x_2, ..., x_n)$\n",
    "\n",
    "- $f(\\mathbf{x}) = \\frac{1}{2} \\mathbf{x}^\\top\\mathbf{A}_1\\mathbf{x} - \\mathbf{b}_1^\\top\\mathbf{x}$,\n",
    "  donde $\\mathbf{A}_1$ y $\\mathbf{b}_1$ están definidas como en el Ejercicio 1.\n",
    "- $\\mathbf{x}_0 = (0,...,0)\\in \\mathbb{R}^{10}$ \n",
    "- $\\mathbf{x}_0 = (0,...,0)\\in \\mathbb{R}^{100}$ \n",
    "- $\\mathbf{x}_0 = (0,...,0)\\in \\mathbb{R}^{1000}$ \n",
    "\n",
    "**Función de cuadrática 2:** Para $\\mathbf{x}=(x_1,x_2, ..., x_n)$\n",
    "\n",
    "- $f(\\mathbf{x}) = \\frac{1}{2} \\mathbf{x}^\\top\\mathbf{A}_2\\mathbf{x} - \\mathbf{b}_2^\\top\\mathbf{x}$,\n",
    "  donde $\\mathbf{A}_2$ y $\\mathbf{b}_2$ están definidas como en el Ejercicio 1.\n",
    "- $\\mathbf{x}_0 = (0,...,0)\\in \\mathbb{R}^{10}$ \n",
    "- $\\mathbf{x}_0 = (0,...,0)\\in \\mathbb{R}^{100}$ \n",
    "- $\\mathbf{x}_0 = (0,...,0)\\in \\mathbb{R}^{1000}$ \n",
    "\n",
    "**Función de Beale :** Para $\\mathbf{x}=(x_1,x_2)$\n",
    "\n",
    "$$f(\\mathbf{x}) = (1.5-x_1 + x_1x_2)^2 + (2.25 - x_1 + x_1x_2^2)^2 + (2.625 - x_1 + x_1x_2^3)^2.$$\n",
    "- $\\mathbf{x}_0 = (2,3)$  \n",
    "   \n",
    "\n",
    "**Función de Himmelblau:** Para $\\mathbf{x}=(x_1,x_2)$\n",
    "\n",
    "$$f(\\mathbf{x}) = (x_1^2 + x_2 - 11)^2 + (x_1 + x_2^2 - 7)^2. $$\n",
    "- $\\mathbf{x}_0 = (2,4)$\n",
    "\n",
    "\n",
    "\n",
    "**Función de Rosenbrock:** Para $\\mathbf{x}=(x_1,x_2, ..., x_n)$\n",
    "\n",
    "$$ f(\\mathbf{x}) = \\sum_{i=1}^{n-1} \\left[100(x_{i+1} - x_i^2)^2 + (1-x_i)^2 \\right]\n",
    "\\quad n\\geq 2.$$\n",
    "- $\\mathbf{x}_0 = (-1.2, 1.0)\\in \\mathbb{R}^{2}$  \n",
    "- $\\mathbf{x}_0 = (-1.2, 1.0, ..., -1.2, 1.0) \\in \\mathbb{R}^{20}$  \n",
    "- $\\mathbf{x}_0 = (-1.2, 1.0, ..., -1.2, 1.0) \\in \\mathbb{R}^{40}$ \n",
    "\n",
    "\n",
    "3. Fije $N=5000$, $\\tau = \\sqrt{n}\\epsilon_m^{1/3}$, donde $n$ es la dimensión\n",
    "   de la variable $\\mathbf{x}$ y $\\epsilon_m$ es el épsilon máquina. \n",
    "   Para backtracking use $\\rho=0.5$, $c_1=0.001$, $c_2=0.01$, $N_b=500$.\n",
    "   \n",
    "4. Para cada función de prueba imprima\n",
    "   \n",
    "- la dimensión $n$,\n",
    "- $f(\\mathbf{x}_0)$,\n",
    "- el  número $k$ de iteraciones realizadas,\n",
    "- $f(\\mathbf{x}_k)$,\n",
    "- las primeras y últimas 4 entradas del punto $\\mathbf{x}_k$ que devuelve el algoritmo,\n",
    "- la norma del vector gradiente $\\mathbf{g}_k$, \n",
    "- la variable $bres$ para saber si el algoritmo puedo converger.\n",
    "- el número de reinicios $nr$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Opti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
